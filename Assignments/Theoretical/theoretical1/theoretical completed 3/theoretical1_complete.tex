\documentclass[11pt]{article}

    \usepackage[breakable]{tcolorbox}
    \usepackage{parskip} % Stop auto-indenting (to mimic markdown behaviour)
    
    \usepackage{iftex}
    \ifPDFTeX
    	\usepackage[T1]{fontenc}
    	\usepackage{mathpazo}
    \else
    	\usepackage{fontspec}
    \fi

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % Maintain compatibility with old templates. Remove in nbconvert 6.0
    \let\Oldincludegraphics\includegraphics
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionFormat{nocaption}{}
    \captionsetup{format=nocaption,aboveskip=0pt,belowskip=0pt}

    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range
    \makeatletter % fix for old versions of grffile with XeLaTeX
    \@ifpackagelater{grffile}{2019/11/01}
    {
      % Do nothing on new versions
    }
    {
      \def\Gread@@xetex#1{%
        \IfFileExists{"\Gin@base".bb}%
        {\Gread@eps{\Gin@base.bb}}%
        {\Gread@@xetex@aux#1}%
      }
    }
    \makeatother
    \usepackage[Export]{adjustbox} % Used to constrain images to a maximum size
    \adjustboxset{max size={0.9\linewidth}{0.9\paperheight}}

    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    % The default LaTeX title has an obnoxious amount of whitespace. By default,
    % titling removes some of it. It also provides customization options.
    \usepackage{titling}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{mathrsfs}
    

    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % common color for the border for error outputs.
    \definecolor{outerrorbackground}{HTML}{FFDFDF}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{theoretical1\_complete}
    
    
    
    
    
% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\@namedef{PY@tok@w}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\@namedef{PY@tok@c}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\@namedef{PY@tok@cp}{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\@namedef{PY@tok@k}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kt}{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\@namedef{PY@tok@o}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ow}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@nb}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nf}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@ne}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\@namedef{PY@tok@nv}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@no}{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\@namedef{PY@tok@nl}{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\@namedef{PY@tok@ni}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\@namedef{PY@tok@na}{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\@namedef{PY@tok@nt}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nd}{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@s}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sd}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@si}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\@namedef{PY@tok@se}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\@namedef{PY@tok@sr}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\@namedef{PY@tok@ss}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sx}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@m}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@gh}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@gu}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\@namedef{PY@tok@gd}{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\@namedef{PY@tok@gi}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\@namedef{PY@tok@gr}{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\@namedef{PY@tok@ge}{\let\PY@it=\textit}
\@namedef{PY@tok@gs}{\let\PY@bf=\textbf}
\@namedef{PY@tok@gp}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@go}{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\@namedef{PY@tok@gt}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\@namedef{PY@tok@err}{\def\PY@bc##1{{\setlength{\fboxsep}{\string -\fboxrule}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}}
\@namedef{PY@tok@kc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kd}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kr}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@bp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@fm}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@vc}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vg}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vi}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vm}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sa}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sb}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sc}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@dl}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s2}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sh}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s1}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@mb}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mf}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mh}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mi}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@il}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mo}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ch}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\@namedef{PY@tok@cm}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\@namedef{PY@tok@cpf}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\@namedef{PY@tok@c1}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\@namedef{PY@tok@cs}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % For linebreaks inside Verbatim environment from package fancyvrb. 
    \makeatletter
        \newbox\Wrappedcontinuationbox 
        \newbox\Wrappedvisiblespacebox 
        \newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}} 
        \newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}} 
        \newcommand*\Wrappedcontinuationindent {3ex } 
        \newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox} 
        % Take advantage of the already applied Pygments mark-up to insert 
        % potential linebreaks for TeX processing. 
        %        {, <, #, %, $, ' and ": go to next line. 
        %        _, }, ^, &, >, - and ~: stay at end of broken line. 
        % Use of \textquotesingle for straight quote. 
        \newcommand*\Wrappedbreaksatspecials {% 
            \def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}% 
            \def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}% 
            \def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}% 
            \def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}% 
            \def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}% 
            \def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}% 
            \def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}% 
            \def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}% 
            \def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}% 
            \def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}% 
            \def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}% 
            \def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}% 
            \def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}% 
            \def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}% 
        } 
        % Some characters . , ; ? ! / are not pygmentized. 
        % This macro makes them "active" and they will insert potential linebreaks 
        \newcommand*\Wrappedbreaksatpunct {% 
            \lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}% 
            \lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}% 
            \lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}% 
            \lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}% 
            \lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}% 
            \lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}% 
            \lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}% 
            \catcode`\.\active
            \catcode`\,\active 
            \catcode`\;\active
            \catcode`\:\active
            \catcode`\?\active
            \catcode`\!\active
            \catcode`\/\active 
            \lccode`\~`\~ 	
        }
    \makeatother

    \let\OriginalVerbatim=\Verbatim
    \makeatletter
    \renewcommand{\Verbatim}[1][1]{%
        %\parskip\z@skip
        \sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
        \sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
        \def\FancyVerbFormatLine ##1{\hsize\linewidth
            \vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
                \doublehyphendemerits\z@\finalhyphendemerits\z@
                \strut ##1\strut}%
        }%
        % If the linebreak is at a space, the latter will be displayed as visible
        % space at end of first line, and a continuation symbol starts next line.
        % Stretch/shrink are however usually zero for typewriter font.
        \def\FV@Space {%
            \nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
            \discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
            {\kern\fontdimen2\font}%
        }%
        
        % Allow breaks at special characters using \PYG... macros.
        \Wrappedbreaksatspecials
        % Breaks at punctuation characters . , ; ? ! and / need catcode=\active 	
        \OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
    }
    \makeatother

    % Exact colors from NB
    \definecolor{incolor}{HTML}{303F9F}
    \definecolor{outcolor}{HTML}{D84315}
    \definecolor{cellborder}{HTML}{CFCFCF}
    \definecolor{cellbackground}{HTML}{F7F7F7}
    
    % prompt
    \makeatletter
    \newcommand{\boxspacing}{\kern\kvtcb@left@rule\kern\kvtcb@boxsep}
    \makeatother
    \newcommand{\prompt}[4]{
        {\ttfamily\llap{{\color{#2}[#3]:\hspace{3pt}#4}}\vspace{-\baselineskip}}
    }
    

    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

\begin{document}
    
    \maketitle
    
    

    
    \hypertarget{tweet-classification-with-naive-bayes---teodor-carlsson}{%
\section{Tweet classification with naive bayes - Teodor
Carlsson}\label{tweet-classification-with-naive-bayes---teodor-carlsson}}

For this notebook we are going to implement a naive bayes classifier for
classifying tweets about Trump or Obama based on the words in the tweet.
Recall that for two events A and B the bayes theorem says

\[ P(A|B) = \frac{P(B|A)P(A)}{P(B)} \]

where P(A) and P(B) is the \textbf{\emph{class probabilities}} and
P(B\textbar A) is called \textbf{\emph{conditional probabilities}}. this
gives us the probability of A happening, given that B has occurred. So
as an example if we want to find the probability of ``is this a tweet
about Trump given that it contains the word''president" " we will obtain
the following

\[ P(\text{"Trump"}|\text{"president" in tweet}) = \frac{P("\text{"president" in tweet}|\text{"Trump"})P(\text{"Trump"})}{P("\text{"president" in tweet})} \]

This means that to find the probability of ``is this a tweet about Trump
given that it contains the word''president" " we need the probability of
``president'' being in a tweet about Trump, the probability of a tweet
being about Trump and the probability of ``president'' being in a tweet.

Similarly if we want to obtain the opposite ``is this a tweet about
Obama given that it contains the word''president" " we get

\[ P(\text{"Obama"}|\text{"president" in tweet}) = \frac{P(\text{"president" in tweet}|\text{"Obama"})P(\text{"Obama"})}{P(\text{"president" in tweet})} \]

where we need the probability of ``president'' being in a tweet about
Obama, the probability of a tweet being about Obama and the probability
of ``president'' being in a tweet.

We can now build a classifier where we compare those two probabilities
and whichever is the larger one it's classified as

if P(``Trump''\textbar{}``president'' in tweet) \(>\)
P(``Obama''\textbar{}``president'' in tweet)

Tweet is about Trump

else

Tweet is about Obama

Now let's expand this to handle multiple features and put the Naive
assumption into bayes theroem. This means that if features are
independent we have

\[ P(A,B) = P(A)P(B) \]

This gives us:

\[ P(A|b_1,b_2,...,b_n) = \frac{P(b_1|A)P(b_2|A)...P(b_n|A)P(A)}{P(b_1)P(b_2)...P(b_n)} \]

or

\[ P(A|b_1,b_2,...,b_n) = \frac{\prod_i^nP(b_i|A)P(A)}{P(b_1)P(b_2)...P(b_n)} \]

So with our previous example expanded with more words ``is this a tweet
about Trump given that it contains the word''president" and ``America''
" gives us

\[ P(\text{"Trump"}|\text{"president", "America" in tweet}) = \frac{P(\text{"president" in tweet}|\text{"Trump"})P(\text{"America" in tweet}|\text{"Trump"})P(\text{"Trump"})}{P(\text{"president" in tweet})P(\text{"America" in tweet})} \]

As you can see the denominator remains constant which means we can
remove it and the final classifier end up

\[y = argmax_A P(A)\prod_i^nP(b_i|A) \]

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{7}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}stuff to import}
\PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
\PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
\PY{k+kn}{import} \PY{n+nn}{random}
\PY{k+kn}{import} \PY{n+nn}{sklearn}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k+kn}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{8}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nb}{print}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{\PYZus{}\PYZus{}version\PYZus{}\PYZus{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{\PYZus{}\PYZus{}version\PYZus{}\PYZus{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{sklearn}\PY{o}{.}\PY{n}{\PYZus{}\PYZus{}version\PYZus{}\PYZus{}}\PY{p}{)}
\PY{k}{if} \PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{\PYZus{}\PYZus{}version\PYZus{}\PYZus{}} \PY{o}{\PYZgt{}} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{1.2.1}\PY{l+s+s2}{\PYZdq{}} \PY{o+ow}{and} \PY{n}{np}\PY{o}{.}\PY{n}{\PYZus{}\PYZus{}version\PYZus{}\PYZus{}} \PY{o}{\PYZgt{}} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{1.19.4}\PY{l+s+s2}{\PYZdq{}} \PY{o+ow}{and} \PY{n}{sklearn}\PY{o}{.}\PY{n}{\PYZus{}\PYZus{}version\PYZus{}\PYZus{}} \PY{o}{\PYZgt{}} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{0.24.0}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{:}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{I assume we}\PY{l+s+s2}{\PYZsq{}}\PY{l+s+s2}{re good to go!}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{c+c1}{\PYZsh{}assert pd.\PYZus{}\PYZus{}version\PYZus{}\PYZus{} == \PYZdq{}1.2.1\PYZdq{}, \PYZdq{}Looks like you don\PYZsq{}t have the same version of pandas as us!\PYZdq{}}
\PY{c+c1}{\PYZsh{}assert np.\PYZus{}\PYZus{}version\PYZus{}\PYZus{} == \PYZdq{}1.19.4\PYZdq{}, \PYZdq{}Looks like you don\PYZsq{}t have the same version of numpy as us!\PYZdq{}}
\PY{c+c1}{\PYZsh{}assert sklearn.\PYZus{}\PYZus{}version\PYZus{}\PYZus{} == \PYZdq{}0.24.0\PYZdq{}, \PYZdq{}Looks like you don\PYZsq{}t have the same version of sklearn as us!\PYZdq{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
1.2.4
1.20.1
0.24.1
I assume we're good to go!
    \end{Verbatim}

    Load the data and explore

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{9}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{df\PYZus{}t} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{trump\PYZus{}20200530.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{trump\PYZus{}tweets} \PY{o}{=} \PY{n}{df\PYZus{}t}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{text}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{n}{df\PYZus{}t} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Tweets\PYZhy{}BarackObama.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{obama\PYZus{}tweets} \PY{o}{=} \PY{n}{df\PYZus{}t}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Tweet\PYZhy{}text}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}

\PY{n}{tweet\PYZus{}data} \PY{o}{=} \PY{n}{trump\PYZus{}tweets}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{obama\PYZus{}tweets}\PY{p}{,} \PY{n}{ignore\PYZus{}index}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n}{tweet\PYZus{}labels} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{T}\PY{l+s+s1}{\PYZsq{}} \PY{k}{for} \PY{n}{\PYZus{}} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{trump\PYZus{}tweets}\PY{p}{)}\PY{p}{)}\PY{p}{]} \PY{o}{+} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{O}\PY{l+s+s1}{\PYZsq{}} \PY{k}{for} \PY{n}{\PYZus{}} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{obama\PYZus{}tweets}\PY{p}{)}\PY{p}{)}\PY{p}{]}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{10}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{lab}\PY{p}{,} \PY{n}{counts} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{unique}\PY{p}{(}\PY{n}{tweet\PYZus{}labels}\PY{p}{,} \PY{n}{return\PYZus{}counts}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Number of tweets about }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{lab}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{counts}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Number of tweets about }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{lab}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{counts}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Number of tweets about  O :  6851
Number of tweets about  T :  18467
    \end{Verbatim}

    As you can see we have many more Trump than Obama Tweets so simlpy
guessing that a tweet is a Trump tweet already gives you a classifier
that is correct about 70\% of the time, but we can do better than this.

Now lets split the data into a training set and a test set using
scikit-learns train\_test\_split function
https://scikit-learn.org/stable/modules/generated/sklearn.model\_selection.train\_test\_split.html

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{11}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Split data into train\PYZus{}tweets, test\PYZus{}tweets, train\PYZus{}labels and test\PYZus{}labels}
\PY{n}{train\PYZus{}tweets}\PY{p}{,} \PY{n}{test\PYZus{}tweets}\PY{p}{,} \PY{n}{train\PYZus{}labels}\PY{p}{,} \PY{n}{test\PYZus{}labels} \PY{o}{=} \PY{n}{sklearn}\PY{o}{.}\PY{n}{model\PYZus{}selection}\PY{o}{.}\PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{tweet\PYZus{}data}\PY{p}{,} \PY{n}{tweet\PYZus{}labels}\PY{p}{)}
\PY{c+c1}{\PYZsh{}understanding the split function:}
\PY{n}{test} \PY{o}{=} \PY{n}{sklearn}\PY{o}{.}\PY{n}{model\PYZus{}selection}\PY{o}{.}\PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{tweet\PYZus{}labels}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{test}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{test}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{test}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
2
18988
6330
    \end{Verbatim}

    What we need to build our classifier is ``probability of tweet about
Obama'' P(O) , ``probability of tweet about Trump'' P(T), ``probability
of word in tweet given tweet about Obama'' P(w\textbar O) and
``probability of word in tweet given tweet about Trump'' P(w\textbar T).
Start by calculating the probability that a tweet is about Obama and
trump respectively

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{12}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{string}
\PY{n}{Ob} \PY{o}{=} \PY{n}{Tr} \PY{o}{=} \PY{n}{total} \PY{o}{=} \PY{l+m+mi}{0}
\PY{k}{if} \PY{n}{lab}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{O}\PY{l+s+s1}{\PYZsq{}} \PY{o+ow}{and} \PY{n}{lab}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{T}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
    \PY{c+c1}{\PYZsh{}We good!}
    \PY{n}{Ob} \PY{o}{=} \PY{n}{counts}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
    \PY{n}{Tr} \PY{o}{=} \PY{n}{counts}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}
\PY{k}{elif} \PY{n}{lab}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{O}\PY{l+s+s1}{\PYZsq{}} \PY{o+ow}{and} \PY{n}{lab}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{T}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
    \PY{c+c1}{\PYZsh{}we also good but they reversed... ok for now}
    \PY{n}{Ob} \PY{o}{=} \PY{n}{counts}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}
    \PY{n}{Tr} \PY{o}{=} \PY{n}{counts}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
\PY{k}{else}\PY{p}{:}
    \PY{k}{raise} \PY{n+ne}{Exception}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Hey something is off with your data..}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{total} \PY{o}{=} \PY{n}{Ob}\PY{o}{+}\PY{n}{Tr}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Ob:}\PY{l+s+si}{\PYZob{}}\PY{n}{Ob}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{, Tr:}\PY{l+s+si}{\PYZob{}}\PY{n}{Tr}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{, total:}\PY{l+s+si}{\PYZob{}}\PY{n}{total}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{n}{P\PYZus{}O} \PY{o}{=} \PY{n}{Ob}\PY{o}{/}\PY{n}{total}
\PY{n}{P\PYZus{}T} \PY{o}{=} \PY{n}{Tr}\PY{o}{/}\PY{n}{total}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{P\PYZus{}O}\PY{p}{,} \PY{n}{P\PYZus{}T}\PY{p}{)}

\PY{c+c1}{\PYZsh{}\PYZsh{} No we can only use our test data!}
\PY{n}{lab}\PY{p}{,} \PY{n}{counts} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{unique}\PY{p}{(}\PY{n}{train\PYZus{}labels}\PY{p}{,} \PY{n}{return\PYZus{}counts}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Number of tweets about }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{lab}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{counts}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Number of tweets about }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{lab}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{counts}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
\PY{n}{total} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{train\PYZus{}tweets}\PY{p}{)}
\PY{n}{Ob} \PY{o}{=} \PY{n}{counts}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
\PY{n}{Tr} \PY{o}{=} \PY{n}{counts}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}
\PY{n}{P\PYZus{}O} \PY{o}{=} \PY{n}{Ob}\PY{o}{/}\PY{n}{total}
\PY{n}{P\PYZus{}T} \PY{o}{=} \PY{n}{Tr}\PY{o}{/}\PY{n}{total}

\PY{n}{train\PYZus{}O\PYZus{}tweets} \PY{o}{=} \PY{p}{[}\PY{p}{]}
\PY{n}{train\PYZus{}T\PYZus{}tweets} \PY{o}{=} \PY{p}{[}\PY{p}{]}
\PY{n}{index} \PY{o}{=} \PY{l+m+mi}{0}
\PY{k}{for} \PY{p}{(}\PY{n}{tw}\PY{p}{,}\PY{n}{lb}\PY{p}{)} \PY{o+ow}{in} \PY{n+nb}{zip}\PY{p}{(}\PY{n}{train\PYZus{}tweets}\PY{p}{,}\PY{n}{train\PYZus{}labels}\PY{p}{)}\PY{p}{:}
    \PY{k}{if} \PY{n}{lb} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{T}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
        \PY{n}{train\PYZus{}T\PYZus{}tweets}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{tw}\PY{p}{)}
    \PY{k}{elif} \PY{n}{lb} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{O}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
        \PY{n}{train\PYZus{}O\PYZus{}tweets}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{tw}\PY{p}{)}
    \PY{k}{else}\PY{p}{:}
        \PY{k}{raise} \PY{n+ne}{Exception}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Unexpected label!}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}      
    \PY{n}{index}\PY{o}{+}\PY{o}{=}\PY{l+m+mi}{1}
\PY{k}{assert}\PY{p}{(}\PY{n}{index}\PY{o}{==}\PY{n}{total}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{len T tweets: }\PY{l+s+si}{\PYZob{}}\PY{n+nb}{len}\PY{p}{(}\PY{n}{train\PYZus{}T\PYZus{}tweets}\PY{p}{)}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{ len O tweets: }\PY{l+s+si}{\PYZob{}}\PY{n+nb}{len}\PY{p}{(}\PY{n}{train\PYZus{}O\PYZus{}tweets}\PY{p}{)}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Ob:6851, Tr:18467, total:25318
0.2705979935223951 0.7294020064776049
Number of tweets about  O :  5209
Number of tweets about  T :  13779
len T tweets: 13779 len O tweets: 5209
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{13}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}create new dict with each word in it to count}
\PY{c+c1}{\PYZsh{} got some help from https://www.geeksforgeeks.org/python\PYZhy{}count\PYZhy{}occurrences\PYZhy{}of\PYZhy{}each\PYZhy{}word\PYZhy{}in\PYZhy{}given\PYZhy{}text\PYZhy{}file\PYZhy{}using\PYZhy{}dictionary/}
\PY{c+c1}{\PYZsh{} as well as from https://datagy.io/python\PYZhy{}remove\PYZhy{}punctuation\PYZhy{}from\PYZhy{}string/}
\PY{c+c1}{\PYZsh{} also this code is fairly repetitive, I should probably refactor it into some function... apologies}
\PY{n}{word\PYZus{}occurrences\PYZus{}unique} \PY{o}{=} \PY{n+nb}{dict}\PY{p}{(}\PY{p}{)} \PY{c+c1}{\PYZsh{}each word is only added maximum once per tweet here}
\PY{k}{for} \PY{n}{tw} \PY{o+ow}{in} \PY{n}{train\PYZus{}tweets}\PY{p}{:}
    \PY{n}{tw} \PY{o}{=} \PY{n}{tw}\PY{o}{.}\PY{n}{lower}\PY{p}{(}\PY{p}{)}
    \PY{n}{tw} \PY{o}{=} \PY{n}{tw}\PY{o}{.}\PY{n}{translate}\PY{p}{(}\PY{n+nb}{str}\PY{o}{.}\PY{n}{maketrans}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
    \PY{n}{words} \PY{o}{=} \PY{n}{tw}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ }\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
    \PY{n}{word\PYZus{}history} \PY{o}{=} \PY{p}{[}\PY{p}{]}
    \PY{k}{for} \PY{n}{word} \PY{o+ow}{in} \PY{n}{words}\PY{p}{:}
        \PY{k}{if} \PY{n}{word} \PY{o+ow}{in} \PY{n}{word\PYZus{}occurrences\PYZus{}unique}\PY{p}{:}
            \PY{k}{if} \PY{n}{word} \PY{o+ow}{not} \PY{o+ow}{in} \PY{n}{word\PYZus{}history}\PY{p}{:}
                \PY{n}{word\PYZus{}occurrences\PYZus{}unique}\PY{p}{[}\PY{n}{word}\PY{p}{]} \PY{o}{=} \PY{n}{word\PYZus{}occurrences\PYZus{}unique}\PY{p}{[}\PY{n}{word}\PY{p}{]} \PY{o}{+} \PY{l+m+mi}{1}
                \PY{n}{word\PYZus{}history}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{word}\PY{p}{)}
        \PY{k}{else}\PY{p}{:}
            \PY{k}{if} \PY{n}{word} \PY{o+ow}{not} \PY{o+ow}{in} \PY{n}{word\PYZus{}history}\PY{p}{:}
                \PY{n}{word\PYZus{}occurrences\PYZus{}unique}\PY{p}{[}\PY{n}{word}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{1}
                \PY{n}{word\PYZus{}history}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{word}\PY{p}{)}
    \PY{n}{word\PYZus{}history} \PY{o}{=} \PY{p}{[}\PY{p}{]}

\PY{n}{word\PYZus{}occurrences\PYZus{}unique\PYZus{}O} \PY{o}{=} \PY{n+nb}{dict}\PY{p}{(}\PY{p}{)} \PY{c+c1}{\PYZsh{}each word is only added maximum once per tweet here}
\PY{k}{for} \PY{n}{tw} \PY{o+ow}{in} \PY{n}{train\PYZus{}O\PYZus{}tweets}\PY{p}{:}
    \PY{n}{tw} \PY{o}{=} \PY{n}{tw}\PY{o}{.}\PY{n}{lower}\PY{p}{(}\PY{p}{)}
    \PY{n}{tw} \PY{o}{=} \PY{n}{tw}\PY{o}{.}\PY{n}{translate}\PY{p}{(}\PY{n+nb}{str}\PY{o}{.}\PY{n}{maketrans}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
    \PY{n}{words} \PY{o}{=} \PY{n}{tw}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ }\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
    \PY{n}{word\PYZus{}history} \PY{o}{=} \PY{p}{[}\PY{p}{]}
    \PY{k}{for} \PY{n}{word} \PY{o+ow}{in} \PY{n}{words}\PY{p}{:}
        \PY{k}{if} \PY{n}{word} \PY{o+ow}{in} \PY{n}{word\PYZus{}occurrences\PYZus{}unique\PYZus{}O}\PY{p}{:}
            \PY{k}{if} \PY{n}{word} \PY{o+ow}{not} \PY{o+ow}{in} \PY{n}{word\PYZus{}history}\PY{p}{:}
                \PY{n}{word\PYZus{}occurrences\PYZus{}unique\PYZus{}O}\PY{p}{[}\PY{n}{word}\PY{p}{]} \PY{o}{=} \PY{n}{word\PYZus{}occurrences\PYZus{}unique\PYZus{}O}\PY{p}{[}\PY{n}{word}\PY{p}{]} \PY{o}{+} \PY{l+m+mi}{1}
                \PY{n}{word\PYZus{}history}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{word}\PY{p}{)}
        \PY{k}{else}\PY{p}{:}
            \PY{k}{if} \PY{n}{word} \PY{o+ow}{not} \PY{o+ow}{in} \PY{n}{word\PYZus{}history}\PY{p}{:}
                \PY{n}{word\PYZus{}occurrences\PYZus{}unique\PYZus{}O}\PY{p}{[}\PY{n}{word}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{1}
                \PY{n}{word\PYZus{}history}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{word}\PY{p}{)}
    \PY{n}{word\PYZus{}history} \PY{o}{=} \PY{p}{[}\PY{p}{]}

\PY{n}{word\PYZus{}occurrences\PYZus{}unique\PYZus{}T} \PY{o}{=} \PY{n+nb}{dict}\PY{p}{(}\PY{p}{)} \PY{c+c1}{\PYZsh{}each word is only added maximum once per tweet here}
\PY{k}{for} \PY{n}{tw} \PY{o+ow}{in} \PY{n}{train\PYZus{}T\PYZus{}tweets}\PY{p}{:}
    \PY{n}{tw} \PY{o}{=} \PY{n}{tw}\PY{o}{.}\PY{n}{lower}\PY{p}{(}\PY{p}{)}
    \PY{n}{tw} \PY{o}{=} \PY{n}{tw}\PY{o}{.}\PY{n}{translate}\PY{p}{(}\PY{n+nb}{str}\PY{o}{.}\PY{n}{maketrans}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
    \PY{n}{words} \PY{o}{=} \PY{n}{tw}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ }\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
    \PY{n}{word\PYZus{}history} \PY{o}{=} \PY{p}{[}\PY{p}{]}
    \PY{k}{for} \PY{n}{word} \PY{o+ow}{in} \PY{n}{words}\PY{p}{:}
        \PY{k}{if} \PY{n}{word} \PY{o+ow}{in} \PY{n}{word\PYZus{}occurrences\PYZus{}unique\PYZus{}T}\PY{p}{:}
            \PY{k}{if} \PY{n}{word} \PY{o+ow}{not} \PY{o+ow}{in} \PY{n}{word\PYZus{}history}\PY{p}{:}
                \PY{n}{word\PYZus{}occurrences\PYZus{}unique\PYZus{}T}\PY{p}{[}\PY{n}{word}\PY{p}{]} \PY{o}{=} \PY{n}{word\PYZus{}occurrences\PYZus{}unique\PYZus{}T}\PY{p}{[}\PY{n}{word}\PY{p}{]} \PY{o}{+} \PY{l+m+mi}{1}
                \PY{n}{word\PYZus{}history}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{word}\PY{p}{)}
        \PY{k}{else}\PY{p}{:}
            \PY{k}{if} \PY{n}{word} \PY{o+ow}{not} \PY{o+ow}{in} \PY{n}{word\PYZus{}history}\PY{p}{:}
                \PY{n}{word\PYZus{}occurrences\PYZus{}unique\PYZus{}T}\PY{p}{[}\PY{n}{word}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{1}
                \PY{n}{word\PYZus{}history}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{word}\PY{p}{)}
    \PY{n}{word\PYZus{}history} \PY{o}{=} \PY{p}{[}\PY{p}{]}

\PY{k}{assert}\PY{p}{(}\PY{n}{word\PYZus{}occurrences\PYZus{}unique\PYZus{}O}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{president}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{+} \PY{n}{word\PYZus{}occurrences\PYZus{}unique\PYZus{}T}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{president}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{==} \PY{n}{word\PYZus{}occurrences\PYZus{}unique}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{president}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    For P(w\textbar O), P(w\textbar T) we need to count how many tweets each
word occur in. Count the number of tweets each word occurs in and store
in the word counter. An entry in the word counter is for instance
\{`president': `O':87, `T': 100\} meaning president occurs in 87 words
about Obaman and 100 tweets about Trump. Be aware that we are not
interested in calculating multiple occurances of the same word in the
same tweet. For each word convert it to lower case. You can use Python's
\href{https://www.w3schools.com/python/ref_string_lower.asp}{lower}.
Another handy Python string method is
\href{https://www.w3schools.com/python/ref_string_split.asp}{split}.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{14}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{word\PYZus{}counter} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{length of tweets obama: }\PY{l+s+si}{\PYZob{}}\PY{n+nb}{len}\PY{p}{(}\PY{n}{obama\PYZus{}tweets}\PY{p}{)}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{ length of tweets trump:}\PY{l+s+si}{\PYZob{}}\PY{n+nb}{len}\PY{p}{(}\PY{n}{trump\PYZus{}tweets}\PY{p}{)}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{ }\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{}attempt 5}
\PY{n}{word\PYZus{}counter} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}
\PY{c+c1}{\PYZsh{}obama}
\PY{k}{for} \PY{n}{key} \PY{o+ow}{in} \PY{n+nb}{list}\PY{p}{(}\PY{n}{word\PYZus{}occurrences\PYZus{}unique\PYZus{}O}\PY{o}{.}\PY{n}{keys}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{:}
    \PY{k}{if} \PY{n}{key} \PY{o+ow}{in} \PY{n}{word\PYZus{}counter}\PY{p}{:}
            \PY{n}{word\PYZus{}counter}\PY{p}{[}\PY{n}{key}\PY{p}{]}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{O}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{word\PYZus{}occurrences\PYZus{}unique\PYZus{}O}\PY{p}{[}\PY{n}{key}\PY{p}{]} \PY{o}{+} \PY{l+m+mi}{1}
    \PY{k}{else}\PY{p}{:}
        \PY{n}{word\PYZus{}counter}\PY{p}{[}\PY{n}{key}\PY{p}{]} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{O}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{T}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+m+mi}{0}\PY{p}{\PYZcb{}}
        \PY{n}{word\PYZus{}counter}\PY{p}{[}\PY{n}{key}\PY{p}{]}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{O}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{word\PYZus{}occurrences\PYZus{}unique\PYZus{}O}\PY{p}{[}\PY{n}{key}\PY{p}{]}
\PY{c+c1}{\PYZsh{}trump}
\PY{k}{for} \PY{n}{key} \PY{o+ow}{in} \PY{n+nb}{list}\PY{p}{(}\PY{n}{word\PYZus{}occurrences\PYZus{}unique\PYZus{}T}\PY{o}{.}\PY{n}{keys}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{:}
    \PY{k}{if} \PY{n}{key} \PY{o+ow}{in} \PY{n}{word\PYZus{}counter}\PY{p}{:}
            \PY{n}{word\PYZus{}counter}\PY{p}{[}\PY{n}{key}\PY{p}{]}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{T}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{word\PYZus{}occurrences\PYZus{}unique\PYZus{}T}\PY{p}{[}\PY{n}{key}\PY{p}{]} \PY{o}{+} \PY{l+m+mi}{1}
    \PY{k}{else}\PY{p}{:}
        \PY{n}{word\PYZus{}counter}\PY{p}{[}\PY{n}{key}\PY{p}{]} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{O}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{T}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+m+mi}{0}\PY{p}{\PYZcb{}}
        \PY{n}{word\PYZus{}counter}\PY{p}{[}\PY{n}{key}\PY{p}{]}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{T}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{word\PYZus{}occurrences\PYZus{}unique\PYZus{}T}\PY{p}{[}\PY{n}{key}\PY{p}{]}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{attempt5}\PY{l+s+si}{\PYZob{}}\PY{n}{word\PYZus{}counter}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{president}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{train\PYZus{}O\PYZus{}tweets}\PY{p}{)}\PY{p}{,}\PY{n+nb}{len}\PY{p}{(}\PY{n}{train\PYZus{}T\PYZus{}tweets}\PY{p}{)}\PY{p}{)}


\PY{n}{train\PYZus{}data} \PY{o}{=} \PY{n}{train\PYZus{}tweets}
\PY{k}{for} \PY{p}{(}\PY{n}{tweet}\PY{p}{,} \PY{n}{label}\PY{p}{)} \PY{o+ow}{in} \PY{n+nb}{zip}\PY{p}{(}\PY{n}{train\PYZus{}data}\PY{p}{,} \PY{n}{train\PYZus{}labels}\PY{p}{)}\PY{p}{:}
    \PY{c+c1}{\PYZsh{} ... Count number of tweets each word occurs in and store in word\PYZus{}counter where an entry looks like ex. \PYZob{}\PYZsq{}word\PYZsq{}: \PYZsq{}O\PYZsq{}:98, \PYZsq{}T\PYZsq{}:10\PYZcb{}}
    \PY{c+c1}{\PYZsh{}i = 1}
    \PY{k}{continue} \PY{c+c1}{\PYZsh{}I\PYZsq{}ve done this elsewhere}
    
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
length of tweets obama: 6851 length of tweets trump:18467
attempt5\{'O': 917, 'T': 1270\}
5209 13779
    \end{Verbatim}

    Lets work with a smaller subset of words. Find the 100 most occuring
words in tweet data.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{15}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{nr\PYZus{}of\PYZus{}words\PYZus{}to\PYZus{}use} \PY{o}{=} \PY{l+m+mi}{100}
\PY{n}{popular\PYZus{}words} \PY{o}{=} \PY{n+nb}{sorted}\PY{p}{(}\PY{n}{word\PYZus{}counter}\PY{o}{.}\PY{n}{items}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{key}\PY{o}{=}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{O}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{+} \PY{n}{x}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{T}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{reverse}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n}{popular\PYZus{}words} \PY{o}{=} \PY{p}{[}\PY{n}{x}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{popular\PYZus{}words}\PY{p}{[}\PY{p}{:}\PY{n}{nr\PYZus{}of\PYZus{}words\PYZus{}to\PYZus{}use}\PY{p}{]}\PY{p}{]}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{popular\PYZus{}words}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
['the', 'to', 'and', 'of', 'a', 'in', 'rt', 'is', 'for', 'on', 'that', 'are',
'our', 'with', 'be', 'will', 'i', 'this', 'president', 'we', 'have', 'great',
'you', 'obama', 'it', 'at', 'has', 'they', '\&amp;', 'not', 'was', 'by', 'all',
'from', 'people', '—president', 'just', 'he', 'who', 'as', 'very', 'my',
'about', 'more', 'your', 'if', 'no', 'their', 'so', 'thank', 'democrats', 'but',
'do', 'get', 'an', 'his', 'new', 'now', 'trump', 'what', 'than', '-', 'out',
'up', 'been', 'time', 'should', '', 'american', 'news', 'big', 'or', 'can',
'many', 'fake', 'make', 'would', 'today', 'never', 'there', 'one',
'@realdonaldtrump', 'country', 'want', 'when', 'house', 'america', 'u.s.',
'congress', 'good', 'like', '@realdonaldtrump:', 'how', 'going', 'me', 'united',
'even', 'states', 'much', 'years']
    \end{Verbatim}

    Now lets compute P(w\textbar O), P(w\textbar T) for the popular words

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{16}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{P\PYZus{}w\PYZus{}given\PYZus{}t} \PY{o}{=} \PY{n+nb}{dict}\PY{p}{(}\PY{p}{)}
\PY{n}{P\PYZus{}w\PYZus{}given\PYZus{}o} \PY{o}{=} \PY{n+nb}{dict}\PY{p}{(}\PY{p}{)}
\PY{k}{for} \PY{n}{word} \PY{o+ow}{in} \PY{n}{popular\PYZus{}words}\PY{p}{:}
    \PY{c+c1}{\PYZsh{}obama}
    \PY{k}{if} \PY{n}{word} \PY{o+ow}{in} \PY{n}{P\PYZus{}w\PYZus{}given\PYZus{}o}\PY{p}{:}
        \PY{k}{assert}\PY{p}{(}\PY{k+kc}{False}\PY{p}{)} \PY{c+c1}{\PYZsh{}should be first and only time}
    \PY{k}{else}\PY{p}{:}
        \PY{n}{word\PYZus{}occurrences\PYZus{}o} \PY{o}{=} \PY{n}{word\PYZus{}counter}\PY{p}{[}\PY{n}{word}\PY{p}{]}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{O}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
        \PY{n}{nr\PYZus{}of\PYZus{}tweets} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{train\PYZus{}O\PYZus{}tweets}\PY{p}{)}
        \PY{n}{P\PYZus{}w\PYZus{}given\PYZus{}o}\PY{p}{[}\PY{n}{word}\PY{p}{]} \PY{o}{=} \PY{n}{word\PYZus{}occurrences\PYZus{}o}\PY{o}{/}\PY{n}{nr\PYZus{}of\PYZus{}tweets}
    \PY{c+c1}{\PYZsh{}trump}
    \PY{k}{if} \PY{n}{word} \PY{o+ow}{in} \PY{n}{P\PYZus{}w\PYZus{}given\PYZus{}t}\PY{p}{:}
        \PY{k}{assert}\PY{p}{(}\PY{k+kc}{False}\PY{p}{)}
    \PY{k}{else}\PY{p}{:}
        \PY{n}{word\PYZus{}occurrences\PYZus{}t} \PY{o}{=} \PY{n}{word\PYZus{}counter}\PY{p}{[}\PY{n}{word}\PY{p}{]}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{T}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
        \PY{n}{nr\PYZus{}of\PYZus{}tweets} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{train\PYZus{}T\PYZus{}tweets}\PY{p}{)}
        \PY{n}{P\PYZus{}w\PYZus{}given\PYZus{}t}\PY{p}{[}\PY{n}{word}\PY{p}{]} \PY{o}{=} \PY{n}{word\PYZus{}occurrences\PYZus{}t}\PY{o}{/}\PY{n}{nr\PYZus{}of\PYZus{}tweets}
    
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{17}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{classifier} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{basis}\PY{l+s+s1}{\PYZsq{}}  \PY{p}{:} \PY{n}{popular\PYZus{}words}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{P(T)}\PY{l+s+s1}{\PYZsq{}}   \PY{p}{:} \PY{n}{P\PYZus{}O}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{P(O)}\PY{l+s+s1}{\PYZsq{}}   \PY{p}{:} \PY{n}{P\PYZus{}T}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{P(w|O)}\PY{l+s+s1}{\PYZsq{}} \PY{p}{:} \PY{n}{P\PYZus{}w\PYZus{}given\PYZus{}o}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{P(w|T)}\PY{l+s+s1}{\PYZsq{}} \PY{p}{:} \PY{n}{P\PYZus{}w\PYZus{}given\PYZus{}t}
    \PY{p}{\PYZcb{}}   
\end{Verbatim}
\end{tcolorbox}

    Write a tweet\_classifier function that takes your trained classifier
and a tweet and returns wether it's about Trump or Obama unsing the
popular words selected. Note that if there are words in the basis words
in our classifier that are not in the tweet we have the opposite
probabilities i.e P(w\_1 occurs )* P(w\_2 does not occur) * \ldots. if
w\_1 occurs and w\_2 does not occur. The function should return wether
the tweet is about Obama or Trump i.e `T' or `O'

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]

\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]

\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]

\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{18}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{math}
\PY{k+kn}{import} \PY{n+nn}{decimal}
\PY{k}{def} \PY{n+nf}{tweet\PYZus{}classifier}\PY{p}{(}\PY{n}{tweet}\PY{p}{,} \PY{n}{classifier\PYZus{}dict}\PY{p}{)}\PY{p}{:}
    \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{} param tweet: string containing tweet message}
\PY{l+s+sd}{        param classifier: dict containing \PYZsq{}basis\PYZsq{} \PYZhy{} training words}
\PY{l+s+sd}{                                          \PYZsq{}P(T)\PYZsq{} \PYZhy{} class probabilities}
\PY{l+s+sd}{                                          \PYZsq{}P(O)\PYZsq{} \PYZhy{} class probabilities}
\PY{l+s+sd}{                                          \PYZsq{}P(w|O)\PYZsq{} \PYZhy{} conditional probabilities}
\PY{l+s+sd}{                                          \PYZsq{}P(w|T)\PYZsq{} \PYZhy{} conditional probabilities}
\PY{l+s+sd}{        }
\PY{l+s+sd}{        return: either \PYZsq{}T\PYZsq{} or \PYZsq{}O\PYZsq{}}
\PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
    \PY{n}{words\PYZus{}in\PYZus{}tweet} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{unique}\PY{p}{(}\PY{p}{[}\PY{n}{x}\PY{o}{.}\PY{n}{lower}\PY{p}{(}\PY{p}{)} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{tweet}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{p}{)}\PY{p}{]}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} ... Code for classifying tweets using the naive bayes classifier}
    \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}if P(\PYZdq{}trump\PYZdq{}|\PYZdq{}president\PYZdq{} in tweet) \PYZgt{} P(\PYZdq{}obama\PYZdq{}|\PYZdq{}president\PYZdq{} in tweet) }
\PY{l+s+sd}{    then tweet is about trump\PYZdq{}\PYZdq{}\PYZdq{}}   
    \PY{n}{list\PYZus{}of\PYZus{}probabilities} \PY{o}{=} \PY{p}{[}\PY{p}{]} \PY{c+c1}{\PYZsh{}P(\PYZdq{}president\PYZdq{} in tweet|\PYZdq{}trump\PYZdq{}), ... ,P(\PYZdq{}america\PYZdq{} in tweet|\PYZdq{}trump\PYZdq{})}
    \PY{k}{for} \PY{n}{word} \PY{o+ow}{in} \PY{n}{words\PYZus{}in\PYZus{}tweet}\PY{p}{:}
        \PY{k}{try}\PY{p}{:} 
            \PY{n}{list\PYZus{}of\PYZus{}probabilities}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{P\PYZus{}w\PYZus{}given\PYZus{}o}\PY{p}{[}\PY{n}{word}\PY{p}{]}\PY{p}{)}
        \PY{k}{except} \PY{n+ne}{KeyError}\PY{p}{:}
            \PY{c+c1}{\PYZsh{}word does not exist in training data}
            \PY{n}{list\PYZus{}of\PYZus{}probabilities}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)} \PY{c+c1}{\PYZsh{}we ignore new words by multiplying with 1 (new unseen words don\PYZsq{}t help with classification)}
    \PY{n}{prob\PYZus{}products} \PY{o}{=} \PY{n}{math}\PY{o}{.}\PY{n}{prod}\PY{p}{(}\PY{n}{list\PYZus{}of\PYZus{}probabilities}\PY{p}{)} \PY{c+c1}{\PYZsh{}P(\PYZdq{}president\PYZdq{} in tweet|\PYZdq{}obama\PYZdq{})*...*P(\PYZdq{}america\PYZdq{} in tweet|\PYZdq{}obama\PYZdq{})}
    \PY{n}{nominator\PYZus{}o} \PY{o}{=} \PY{n}{P\PYZus{}O} \PY{o}{*} \PY{n}{prob\PYZus{}products} \PY{c+c1}{\PYZsh{}P(\PYZdq{}obama) * P(\PYZdq{}president\PYZdq{} in tweet|\PYZdq{}obama\PYZdq{})*...*P(\PYZdq{}america\PYZdq{} in tweet|\PYZdq{}obama\PYZdq{})}
    
    \PY{c+c1}{\PYZsh{}trump}
    \PY{n}{list\PYZus{}of\PYZus{}probabilities} \PY{o}{=} \PY{p}{[}\PY{p}{]} \PY{c+c1}{\PYZsh{}P(\PYZdq{}president\PYZdq{} in tweet|\PYZdq{}trump\PYZdq{}), ... ,P(\PYZdq{}america\PYZdq{} in tweet|\PYZdq{}trump\PYZdq{})}
    \PY{k}{for} \PY{n}{word} \PY{o+ow}{in} \PY{n}{words\PYZus{}in\PYZus{}tweet}\PY{p}{:}
        \PY{k}{try}\PY{p}{:} 
            \PY{n}{list\PYZus{}of\PYZus{}probabilities}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{P\PYZus{}w\PYZus{}given\PYZus{}t}\PY{p}{[}\PY{n}{word}\PY{p}{]}\PY{p}{)}
        \PY{k}{except} \PY{n+ne}{KeyError}\PY{p}{:}
            \PY{c+c1}{\PYZsh{}word does not exist in training data}
            \PY{n}{list\PYZus{}of\PYZus{}probabilities}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)} \PY{c+c1}{\PYZsh{}we ignore new words by multiplying with 1 (new unseen words don\PYZsq{}t help with classification)}
    \PY{n}{prob\PYZus{}products} \PY{o}{=} \PY{n}{math}\PY{o}{.}\PY{n}{prod}\PY{p}{(}\PY{n}{list\PYZus{}of\PYZus{}probabilities}\PY{p}{)} \PY{c+c1}{\PYZsh{}P(\PYZdq{}president\PYZdq{} in tweet|\PYZdq{}obama\PYZdq{})*...*P(\PYZdq{}america\PYZdq{} in tweet|\PYZdq{}obama\PYZdq{})}
    \PY{n}{nominator\PYZus{}t} \PY{o}{=} \PY{n}{P\PYZus{}T} \PY{o}{*} \PY{n}{prob\PYZus{}products} \PY{c+c1}{\PYZsh{}P(\PYZdq{}obama) * P(\PYZdq{}president\PYZdq{} in tweet|\PYZdq{}obama\PYZdq{})*...*P(\PYZdq{}america\PYZdq{} in tweet|\PYZdq{}obama\PYZdq{})}



    \PY{n}{list\PYZus{}of\PYZus{}probabilities} \PY{o}{=} \PY{p}{[}\PY{p}{]} \PY{c+c1}{\PYZsh{}P(\PYZdq{}president\PYZdq{} in tweet), ... ,P(\PYZdq{}america\PYZdq{} in tweet)}
    \PY{k}{for} \PY{n}{word} \PY{o+ow}{in} \PY{n}{words\PYZus{}in\PYZus{}tweet}\PY{p}{:}
        \PY{k}{try}\PY{p}{:} 
            \PY{n}{P\PYZus{}w} \PY{o}{=} \PY{n}{word\PYZus{}occurrences\PYZus{}unique}\PY{p}{[}\PY{n}{word}\PY{p}{]}
            \PY{n}{list\PYZus{}of\PYZus{}probabilities}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{P\PYZus{}w}\PY{p}{)}
        \PY{k}{except} \PY{n+ne}{KeyError}\PY{p}{:}
            \PY{c+c1}{\PYZsh{}word does not exist in training data}
            \PY{n}{list\PYZus{}of\PYZus{}probabilities}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)} \PY{c+c1}{\PYZsh{}we ignore new words by multiplying with 1 (new unseen words don\PYZsq{}t help with classification)}
    \PY{n}{prob\PYZus{}products} \PY{o}{=} \PY{n}{math}\PY{o}{.}\PY{n}{prod}\PY{p}{(}\PY{n}{list\PYZus{}of\PYZus{}probabilities}\PY{p}{)} \PY{c+c1}{\PYZsh{}P(\PYZdq{}president\PYZdq{} in tweet|\PYZdq{}obama\PYZdq{})*...*P(\PYZdq{}america\PYZdq{} in tweet|\PYZdq{}obama\PYZdq{})}
    \PY{n}{denominator} \PY{o}{=} \PY{n}{prob\PYZus{}products} \PY{c+c1}{\PYZsh{}P(\PYZdq{}president\PYZdq{} in tweet)*...*P(\PYZdq{}america\PYZdq{} in tweet)}
    \PY{c+c1}{\PYZsh{}print(probs)}
    \PY{n}{denominator} \PY{o}{=} \PY{l+m+mi}{1} \PY{c+c1}{\PYZsh{}because denom is constant, remove it avoids floating point errors and overflows in divisions}
    \PY{n}{P\PYZus{}o\PYZus{}given\PYZus{}w} \PY{o}{=} \PY{n}{nominator\PYZus{}o}\PY{o}{/}\PY{n}{denominator} 
    \PY{n}{P\PYZus{}t\PYZus{}given\PYZus{}w} \PY{o}{=} \PY{n}{nominator\PYZus{}t}\PY{o}{/}\PY{n}{denominator}

    \PY{c+c1}{\PYZsh{}naivest way to do it:}
    \PY{c+c1}{\PYZsh{}P\PYZus{}t\PYZus{}given\PYZus{}w = 0.7}
    \PY{c+c1}{\PYZsh{}P\PYZus{}o\PYZus{}given\PYZus{}w = 0.3}

    \PY{k}{if} \PY{n}{P\PYZus{}t\PYZus{}given\PYZus{}w} \PY{o}{\PYZgt{}} \PY{n}{P\PYZus{}o\PYZus{}given\PYZus{}w}\PY{p}{:}
        \PY{k}{return} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{T}\PY{l+s+s1}{\PYZsq{}}
    \PY{k}{else}\PY{p}{:}
        \PY{k}{return} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{O}\PY{l+s+s1}{\PYZsq{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{19}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{test\PYZus{}classifier}\PY{p}{(}\PY{n}{classifier}\PY{p}{,} \PY{n}{test\PYZus{}tweets}\PY{p}{,} \PY{n}{test\PYZus{}labels}\PY{p}{)}\PY{p}{:}
    \PY{n}{total} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{test\PYZus{}tweets}\PY{p}{)}
    \PY{n}{correct} \PY{o}{=} \PY{l+m+mi}{0}
    \PY{k}{for} \PY{p}{(}\PY{n}{tweet}\PY{p}{,}\PY{n}{label}\PY{p}{)} \PY{o+ow}{in} \PY{n+nb}{zip}\PY{p}{(}\PY{n}{test\PYZus{}tweets}\PY{p}{,} \PY{n}{test\PYZus{}labels}\PY{p}{)}\PY{p}{:}
        \PY{n}{predicted} \PY{o}{=} \PY{n}{tweet\PYZus{}classifier}\PY{p}{(}\PY{n}{tweet}\PY{p}{,}\PY{n}{classifier}\PY{p}{)}
        \PY{k}{if} \PY{n}{predicted} \PY{o}{==} \PY{n}{label}\PY{p}{:}
            \PY{n}{correct} \PY{o}{=} \PY{n}{correct} \PY{o}{+} \PY{l+m+mi}{1}
    \PY{k}{return}\PY{p}{(}\PY{n}{correct}\PY{o}{/}\PY{n}{total}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{20}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{acc} \PY{o}{=} \PY{n}{test\PYZus{}classifier}\PY{p}{(}\PY{n}{classifier}\PY{p}{,} \PY{n}{test\PYZus{}tweets}\PY{p}{,} \PY{n}{test\PYZus{}labels}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy: }\PY{l+s+si}{\PYZob{}}\PY{n}{acc}\PY{l+s+si}{:}\PY{l+s+s2}{.4f}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Accuracy: 0.8275
    \end{Verbatim}


    % Add a bibliography block to the postdoc
    
    
    
\end{document}
